{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "%pip install -q \"openvino>=2023.1.0\" opencv-python tqdm\n",
    "\n",
    "if platform.system() != \"Windows\":\n",
    "    %pip install -q \"matplotlib>=3.4\"\n",
    "else:\n",
    "    %pip install -q \"matplotlib>=3.4,<3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openvino as ov\n",
    "import ipywidgets as widgets\n",
    "# Fetch `notebook_utils` module\n",
    "import requests\n",
    "\n",
    "r = requests.get(\n",
    "    url=\"https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py\",\n",
    ")\n",
    "\n",
    "open(\"notebook_utils.py\", \"w\").write(r.text)\n",
    "\n",
    "import notebook_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A directory where the model will be downloaded.\n",
    "base_model_dir = Path(\"model\")\n",
    "# The name of the model from Open Model Zoo.\n",
    "detection_model_name = \"vehicle-detection-0200\"\n",
    "recognition_model_name = \"vehicle-attributes-recognition-barrier-0039\"\n",
    "# Selected precision (FP32, FP16, FP16-INT8)\n",
    "precision = \"FP32\"\n",
    "\n",
    "base_model_url = \"https://storage.openvinotoolkit.org/repositories/open_model_zoo/2023.0/models_bin/1\"\n",
    "\n",
    "# Check if the model exists.\n",
    "detection_model_url = f\"{base_model_url}/{detection_model_name}/{precision}/{detection_model_name}.xml\"\n",
    "recognition_model_url = f\"{base_model_url}/{recognition_model_name}/{precision}/{recognition_model_name}.xml\"\n",
    "detection_model_path = (base_model_dir / detection_model_name).with_suffix(\".xml\")\n",
    "recognition_model_path = (base_model_dir / recognition_model_name).with_suffix(\".xml\")\n",
    "\n",
    "# Download the detection model.\n",
    "if not detection_model_path.exists():\n",
    "    utils.download_file(detection_model_url, detection_model_name + \".xml\", base_model_dir)\n",
    "    utils.download_file(\n",
    "        detection_model_url.replace(\".xml\", \".bin\"),\n",
    "        detection_model_name + \".bin\",\n",
    "        base_model_dir,\n",
    "    )\n",
    "# Download the recognition model.\n",
    "if not os.path.exists(recognition_model_path):\n",
    "    utils.download_file(recognition_model_url, recognition_model_name + \".xml\", base_model_dir)\n",
    "    utils.download_file(\n",
    "        recognition_model_url.replace(\".xml\", \".bin\"),\n",
    "        recognition_model_name + \".bin\",\n",
    "        base_model_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "core = ov.Core()\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value=\"AUTO\",\n",
    "    description=\"Device:\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenVINO Runtime runtime.\n",
    "core = ov.Core()\n",
    "def model_init(model_path: str) -> Tuple:\n",
    "    \"\"\"\n",
    "    Read the network and weights from file, load the\n",
    "    model on the CPU and get input and output names of nodes\n",
    "\n",
    "    :param: model: model architecture path *.xml\n",
    "    :retuns:\n",
    "            input_key: Input node network\n",
    "            output_key: Output node network\n",
    "            exec_net: Encoder model network\n",
    "            net: Model network\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the network and corresponding weights from a file.\n",
    "    model = core.read_model(model=model_path)\n",
    "    compiled_model = core.compile_model(model=model, device_name=device.value)\n",
    "    # Get input and output names of nodes.\n",
    "    input_keys = compiled_model.input(0)\n",
    "    output_keys = compiled_model.output(0)\n",
    "    return input_keys, output_keys, compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de -> detection\n",
    "# re -> recognition\n",
    "# Detection model initialization.\n",
    "input_key_de, output_keys_de, compiled_model_de = model_init(detection_model_path)\n",
    "# Recognition model initialization.\n",
    "input_key_re, output_keys_re, compiled_model_re = model_init(recognition_model_path)\n",
    "\n",
    "# Get input size - Detection.\n",
    "height_de, width_de = list(input_key_de.shape)[2:]\n",
    "# Get input size - Recognition.\n",
    "height_re, width_re = list(input_key_re.shape)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_show(raw_image):\n",
    "    \"\"\"\n",
    "    Use matplot to show image inline\n",
    "    raw_image: input image\n",
    "\n",
    "    :param: raw_image:image array\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image.\n",
    "url = \"https://www.youtube.com/watch?v=iJZcjZD0fw0\"\n",
    "filename = \"traffic.jpg\"\n",
    "directory = \"data\"\n",
    "image_file = utils.download_file(\n",
    "    url,\n",
    "    filename=filename,\n",
    "    directory=directory,\n",
    "    show_progress=False,\n",
    "    silent=True,\n",
    "    timeout=30,\n",
    ")\n",
    "assert Path(image_file).exists()\n",
    "\n",
    "# Read the image.\n",
    "image_de = cv2.imread(f\"{directory}/{filename}\")\n",
    "# Resize it to [3, 256, 256].\n",
    "resized_image_de = cv2.resize(image_de, (width_de, height_de))\n",
    "# Expand the batch channel to [1, 3, 256, 256].\n",
    "input_image_de = np.expand_dims(resized_image_de.transpose(2, 0, 1), 0)\n",
    "# Show the image.\n",
    "plt_show(cv2.cvtColor(image_de, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference.\n",
    "boxes = compiled_model_de([input_image_de])[output_keys_de]\n",
    "# Delete the dim of 0, 1.\n",
    "boxes = np.squeeze(boxes, (0, 1))\n",
    "# Remove zero only boxes.\n",
    "boxes = boxes[~np.all(boxes == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_images(bgr_image, resized_image, boxes, threshold=0.6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Use bounding boxes from detection model to find the absolute car position\n",
    "\n",
    "    :param: bgr_image: raw image\n",
    "    :param: resized_image: resized image\n",
    "    :param: boxes: detection model returns rectangle position\n",
    "    :param: threshold: confidence threshold\n",
    "    :returns: car_position: car's absolute position\n",
    "    \"\"\"\n",
    "    # Fetch image shapes to calculate ratio\n",
    "    (real_y, real_x), (resized_y, resized_x) = (\n",
    "        bgr_image.shape[:2],\n",
    "        resized_image.shape[:2],\n",
    "    )\n",
    "    ratio_x, ratio_y = real_x / resized_x, real_y / resized_y\n",
    "\n",
    "    # Find the boxes ratio\n",
    "    boxes = boxes[:, 2:]\n",
    "    # Store the vehicle's position\n",
    "    car_position = []\n",
    "    # Iterate through non-zero boxes\n",
    "    for box in boxes:\n",
    "        # Pick confidence factor from last place in array\n",
    "        conf = box[0]\n",
    "        if conf > threshold:\n",
    "            # Convert float to int and multiply corner position of each box by x and y ratio\n",
    "            # In case that bounding box is found at the top of the image,\n",
    "            # upper box  bar should be positioned a little bit lower to make it visible on image\n",
    "            (x_min, y_min, x_max, y_max) = [\n",
    "                (int(max(corner_position * ratio_y * resized_y, 10)) if idx % 2 else int(corner_position * ratio_x * resized_x))\n",
    "                for idx, corner_position in enumerate(box[1:])\n",
    "            ]\n",
    "\n",
    "            car_position.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "    return car_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the position of a car.\n",
    "car_position = crop_images(image_de, resized_image_de, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a vehicle to recognize.\n",
    "pos = car_position[0]\n",
    "# Crop the image with [y_min:y_max, x_min:x_max].\n",
    "test_car = image_de[pos[1] : pos[3], pos[0] : pos[2]]\n",
    "# Resize the image to input_size.\n",
    "resized_image_re = cv2.resize(test_car, (width_re, height_re))\n",
    "input_image_re = np.expand_dims(resized_image_re.transpose(2, 0, 1), 0)\n",
    "plt_show(cv2.cvtColor(resized_image_re, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicle_recognition(compiled_model_re, input_size, raw_image):\n",
    "    \"\"\"\n",
    "    Vehicle attributes recognition, input a single vehicle, return attributes\n",
    "    :param: compiled_model_re: recognition net\n",
    "    :param: input_size: recognition input size\n",
    "    :param: raw_image: single vehicle image\n",
    "    :returns: attr_color: predicted color\n",
    "                       attr_type: predicted type\n",
    "    \"\"\"\n",
    "    # An attribute of a vehicle.\n",
    "    colors = [\"White\", \"Gray\", \"Yellow\", \"Red\", \"Green\", \"Blue\", \"Black\"]\n",
    "    types = [\"Car\", \"Bus\", \"Truck\", \"Van\"]\n",
    "\n",
    "    # Resize the image to input size.\n",
    "    resized_image_re = cv2.resize(raw_image, input_size)\n",
    "    input_image_re = np.expand_dims(resized_image_re.transpose(2, 0, 1), 0)\n",
    "\n",
    "    # Run inference.\n",
    "    # Predict result.\n",
    "    predict_colors = compiled_model_re([input_image_re])[compiled_model_re.output(1)]\n",
    "    # Delete the dim of 2, 3.\n",
    "    predict_colors = np.squeeze(predict_colors, (2, 3))\n",
    "    predict_types = compiled_model_re([input_image_re])[compiled_model_re.output(0)]\n",
    "    predict_types = np.squeeze(predict_types, (2, 3))\n",
    "\n",
    "    attr_color, attr_type = (\n",
    "        colors[np.argmax(predict_colors)],\n",
    "        types[np.argmax(predict_types)],\n",
    "    )\n",
    "    return attr_color, attr_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Attributes:{vehicle_recognition(compiled_model_re, (72, 72), test_car)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_image(compiled_model_re, bgr_image, resized_image, boxes, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Use Detection model boxes to draw rectangles and plot the result\n",
    "\n",
    "    :param: compiled_model_re: recognition net\n",
    "    :param: input_key_re: recognition input key\n",
    "    :param: bgr_image: raw image\n",
    "    :param: resized_image: resized image\n",
    "    :param: boxes: detection model returns rectangle position\n",
    "    :param: threshold: confidence threshold\n",
    "    :returns: rgb_image: processed image\n",
    "    \"\"\"\n",
    "    # Define colors for boxes and descriptions.\n",
    "    colors = {\"red\": (255, 0, 0), \"green\": (0, 255, 0)}\n",
    "\n",
    "    # Convert the base image from BGR to RGB format.\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find positions of cars.\n",
    "    car_positions = crop_images(bgr_image, resized_image, boxes, threshold)\n",
    "\n",
    "    for x_min, y_min, x_max, y_max in car_positions:\n",
    "        # Check if the bounding box is valid (ensure it doesn't go out of bounds)\n",
    "        if x_min < 0 or y_min < 0 or x_max > bgr_image.shape[1] or y_max > bgr_image.shape[0]:\n",
    "            print(f\"Invalid bounding box: {(x_min, y_min, x_max, y_max)}\")\n",
    "            continue  # Skip this invalid bounding box\n",
    "\n",
    "        # Crop the detected car from the original image.\n",
    "        cropped_car = bgr_image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Check if the cropped car image is empty.\n",
    "        if cropped_car.size == 0:\n",
    "            print(f\"Empty image for bounding box: {(x_min, y_min, x_max, y_max)}\")\n",
    "            continue  # Skip empty images\n",
    "\n",
    "        # Run vehicle recognition inference.\n",
    "        attr_color, attr_type = vehicle_recognition(compiled_model_re, (72, 72), cropped_car)\n",
    "\n",
    "        # Draw a bounding box around the detected car.\n",
    "        rgb_image = cv2.rectangle(rgb_image, (x_min, y_min), (x_max, y_max), colors[\"red\"], 2)\n",
    "\n",
    "        # Display the predicted color and type of the vehicle.\n",
    "        rgb_image = cv2.putText(\n",
    "            rgb_image,\n",
    "            f\"{attr_color} {attr_type}\",\n",
    "            (x_min, y_min - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,  # Adjust font size to fit text on image\n",
    "            colors[\"green\"],\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return rgb_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results with multiple vehicle detections and recognition.\n",
    "plt_show(convert_result_to_image(compiled_model_re, image_de, resized_image_de, boxes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
